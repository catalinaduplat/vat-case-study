{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scheduled data pipeline to load VAT rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WORKFLOW MANAGEMENT TOOL SELECTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"resources/images/etl-comparison.png\" width=\"850\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ARCHITECTURE DEFINITION**\n",
    "\n",
    "- **Harbor**: Harbor is an open source cloud native registry that stores, signs, and scans container images for vulnerabilities.\n",
    "- **AWS Batch**: Dynamically allocates the resources to run the container, so there's no need to run a machine all the time.\n",
    "- **Cloudwatch**: Monitoring and observability service. Run pipeline at 00:00 am (UTC) every day\n",
    "- **Snowflake**: Snowflake comes with a Python connector, allowing us to use code to fire SQL queries to Snowflake to transform and aggregate data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA MERGE AND VERSIONING ON TARGET TABLES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First idea which comes to mind is that we can overwrite the existing information and forget about the previous one. But by doing so, important information is deleted.\n",
    "\n",
    "Ideas:\n",
    "1. Create a daily version of the VATRates table? -> Might be inefficient - data should not change that frequently.\n",
    "2. We can use the <code>last_updated</code> value of the JSON to check if data was changed, added (countries), or deleted (countries). \n",
    "    - First option: In case data has changed (<code>last_updated</code> is greater than the previous <code>last_updated</code> date), we insert new values to the target table (VATRates) with the new date. This is easier to do, but querying might get tricky as there will be duplicate values. Also, as there will 2+ IDs to represent 1 record, it would become really hard to link other tables we might add in the future.\n",
    "    - **Second option**: In case data has changed (<code>last_updated</code> is greater than the previous <code>last_updated</code> date), then we move the records in VATRates table to VATRatesHistory table and update the values in the target table. This process is more complex, it requires an additional table (but might allow to visualize data better), and querying would be easier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ARCHITECTURE DIAGRAM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](resources/images/pipeline-architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREFECT WORKFLOW STRUCTURE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pytz\n",
    "from datetime import datetime, timedelta\n",
    "from prefect import task, Flow, Parameter\n",
    "import snowflake.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def extract(url: str) -> dict:\n",
    "    res = requests.get(url)\n",
    "    if not res:\n",
    "        raise Exception('No data fetched')\n",
    "    return json.loads(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def connect_db():\n",
    "    \"\"\"\n",
    "    Connect to Snowflake database and return cursor\n",
    "    \"\"\"\n",
    "    # con_eb = snowflake.connector.connect(...)         \n",
    "    # return con_eb.cursor()\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def query_db(cursor) -> bool:\n",
    "    query = 'SELECT * FROM VATRates;'\n",
    "    \"\"\"\n",
    "        With query and connection get if table has data already loaded\n",
    "    \"\"\"\n",
    "    # cursor.execute(query)\n",
    "    # exists = bool(cur.fetchone())\n",
    "    # return exists\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(data: dict) -> pd.DataFrame:\n",
    "    print(data)\n",
    "    \"\"\"\n",
    "        Transform data:\n",
    "        Convert last_updated string to datetime type \n",
    "        Create dataframe with rates information and last_updated date value\n",
    "        Replace missing values with 0's\n",
    "        Transform numeric column types to float\n",
    "    \"\"\"\n",
    "    return pd.DataFrame([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def transform(data: dict, data_loaded: bool) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        Transform process will be carried out only if it's the first load or data needs to be updated\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame([])\n",
    "    last_updated = datetime.strptime(data['last_updated'], \"%Y-%m-%dT%H:%M%z\")\n",
    "    update_needed = False\n",
    "\n",
    "    if data_loaded:\n",
    "        now_date = datetime.now().replace(tzinfo=pytz.UTC)\n",
    "        if now_date-timedelta(hours=24) <= last_updated <= now_date:\n",
    "            df = transform_df(data)\n",
    "            update_needed = True\n",
    "    else:\n",
    "        df = transform_df(data)\n",
    "            \n",
    "    return {'vat_rates': df, 'update_needed': update_needed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def load(data: dict, db_cursor) -> None:\n",
    "    \"\"\"\n",
    "        Load data into Snowflake database only if it's the first load or data needs to be updated\n",
    "    \"\"\"\n",
    "    if len(data['vat_rates']) > 0:\n",
    "        if data['update_needed']:\n",
    "            print('Executing transaction...')\n",
    "            # Create query for transaction:\n",
    "            # 1. Insert data from VATRates to VATRatesHistory\n",
    "            # 2. Delete data from VATRates\n",
    "            # 3. Create insert query from dataframe\n",
    "            # 4. Execute transaction: db_cursor.execute(query)\n",
    "        else:\n",
    "            print('Inserting data to table for first time...')\n",
    "            # 1. Create insert query from dataframe\n",
    "            # 2. Execute query: db_cursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefect_flow():\n",
    "    with Flow(name='vat_rates_etl_pipeline') as flow:\n",
    "        param_url = Parameter(name='rates_url', required=True)\n",
    "        # Database connection\n",
    "        db_cursor = connect_db()\n",
    "        data_loaded = query_db(db_cursor)\n",
    "        \n",
    "        # Extract data from GitHub\n",
    "        vat_info = extract(url=param_url)\n",
    "        \n",
    "        # Transform data\n",
    "        data = transform(vat_info, data_loaded)\n",
    "        \n",
    "        # Load data to database\n",
    "        load(data, db_cursor)\n",
    "    return flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-04 10:19:25-0500] INFO - prefect.FlowRunner | Beginning Flow run for 'vat_rates_etl_pipeline'\n",
      "[2022-03-04 10:19:25-0500] INFO - prefect.TaskRunner | Task 'connect_db': Starting task run...\n",
      "[2022-03-04 10:19:26-0500] INFO - prefect.TaskRunner | Task 'connect_db': Finished task run for task with final state: 'Success'\n",
      "[2022-03-04 10:19:26-0500] INFO - prefect.TaskRunner | Task 'rates_url': Starting task run...\n",
      "[2022-03-04 10:19:26-0500] INFO - prefect.TaskRunner | Task 'rates_url': Finished task run for task with final state: 'Success'\n",
      "[2022-03-04 10:19:26-0500] INFO - prefect.TaskRunner | Task 'query_db': Starting task run...\n",
      "[2022-03-04 10:19:26-0500] INFO - prefect.TaskRunner | Task 'query_db': Finished task run for task with final state: 'Success'\n",
      "[2022-03-04 10:19:26-0500] INFO - prefect.TaskRunner | Task 'extract': Starting task run...\n",
      "[2022-03-04 10:19:26-0500] INFO - prefect.TaskRunner | Task 'extract': Finished task run for task with final state: 'Success'\n",
      "[2022-03-04 10:19:26-0500] INFO - prefect.TaskRunner | Task 'transform': Starting task run...\n",
      "[2022-03-04 10:19:26-0500] INFO - prefect.TaskRunner | Task 'transform': Finished task run for task with final state: 'Success'\n",
      "[2022-03-04 10:19:26-0500] INFO - prefect.TaskRunner | Task 'load': Starting task run...\n",
      "[2022-03-04 10:19:27-0500] INFO - prefect.TaskRunner | Task 'load': Finished task run for task with final state: 'Success'\n",
      "[2022-03-04 10:19:27-0500] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    flow = prefect_flow()\n",
    "    flow.run(parameters={\n",
    "        'rates_url': 'https://raw.githubusercontent.com/benbucksch/eu-vat-rates/ce7a777b7bbdcc94e352d816282647271f6baebf/rates.json'\n",
    "    })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
